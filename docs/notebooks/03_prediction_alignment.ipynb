{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Prediction Alignment: From Sequences to Aligned Predictions\n",
    "\n",
    "Complete workflow from generating variant sequences to running model predictions and aligning them for comparison. Core functionality for analyzing how genetic variants affect model predictions.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Generate reference and alternate sequences around variants\n",
    "- Run mock genomic models (1D and 2D predictions)\n",
    "- Align predictions to account for coordinate changes from variants\n",
    "- Visualize prediction differences between reference and alternate alleles\n",
    "\n",
    "## The Complete Workflow\n",
    "\n",
    "```\n",
    "Reference Genome + VCF\n",
    "        ↓\n",
    "get_alt_ref_sequences()\n",
    "        ↓\n",
    "Reference & Alternate Sequences\n",
    "        ↓\n",
    "TestModel / TestModel2D\n",
    "        ↓\n",
    "Reference & Alternate Predictions\n",
    "        ↓\n",
    "align_predictions_by_coordinate()\n",
    "        ↓\n",
    "Aligned Predictions (ready for comparison!)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supremo_lite version: 0.5.4\n",
      "PyTorch available: True\n",
      "\n",
      "Loaded 8 variants from test data\n"
     ]
    }
   ],
   "source": [
    "import supremo_lite as sl\n",
    "from supremo_lite.mock_models import TestModel, TestModel2D, TORCH_AVAILABLE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyfaidx import Fasta\n",
    "import os\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Check PyTorch availability\n",
    "if not TORCH_AVAILABLE:\n",
    "    raise ImportError(\"PyTorch is required for this notebook. Install with: pip install torch\")\n",
    "\n",
    "print(f\"supremo_lite version: {sl.__version__}\")\n",
    "print(f\"PyTorch available: {TORCH_AVAILABLE}\")\n",
    "\n",
    "# Load test data\n",
    "test_data_dir = \"../../tests/data\"\n",
    "reference = Fasta(os.path.join(test_data_dir, \"test_genome.fa\"))\n",
    "variants = sl.read_vcf(os.path.join(test_data_dir, \"multi\", \"multi.vcf\"))\n",
    "\n",
    "print(f\"\\nLoaded {len(variants)} variants from test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 1: Generate Reference and Alternate Sequences\n",
    "\n",
    "First, we create sequence windows around each variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequences:\n",
      "  Reference sequences shape: torch.Size([8, 200, 4])\n",
      "  Alternate sequences shape: torch.Size([8, 200, 4])\n",
      "  Number of variants: 8\n",
      "\n",
      "First variant metadata:\n",
      "{'chrom': 'chr1', 'window_start': 0, 'window_end': 200, 'variant_pos0': 9, 'variant_pos1': 10, 'ref': 'A', 'alt': 'T', 'variant_type': 'SNV'}\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences around first variant\n",
    "# We'll use a 200bp window (sufficient for our mock models)\n",
    "seq_len = 200\n",
    "\n",
    "# Note: get_alt_ref_sequences is a generator that yields chunks\n",
    "results = list(sl.get_alt_ref_sequences(\n",
    "    reference_fn=reference,\n",
    "    variants_fn=variants, \n",
    "    seq_len=seq_len,\n",
    "    encode=True  # Get encoded tensors for models\n",
    "))\n",
    "\n",
    "# Unpack from the first chunk\n",
    "alt_seqs, ref_seqs, metadata = results[0]\n",
    "\n",
    "print(f\"Generated sequences:\")\n",
    "print(f\"  Reference sequences shape: {ref_seqs.shape}\")\n",
    "print(f\"  Alternate sequences shape: {alt_seqs.shape}\")\n",
    "print(f\"  Number of variants: {len(metadata)}\")\n",
    "\n",
    "print(\"\\nFirst variant metadata:\")\n",
    "print(metadata.iloc[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Understanding Mock Models\n",
    "\n",
    "Before running predictions, let's understand the mock model architectures:\n",
    "\n",
    "### TestModel (1D Predictions)\n",
    "- **Input**: Sequences of shape `(batch, seq_len, 4)`\n",
    "- **Output**: Predictions of shape `(batch, n_targets, n_bins)`\n",
    "- **Features**:\n",
    "  - `bin_size`: Predictions at lower resolution (e.g., 1 prediction per 8bp)\n",
    "  - `crop_length`: Edge bases removed before prediction\n",
    "  - Multiple targets (e.g., different histone marks)\n",
    "\n",
    "### TestModel2D (2D Contact Map Predictions)\n",
    "- **Input**: Sequences of shape `(batch, seq_len, 4)`\n",
    "- **Output**: Predictions of shape `(batch, n_targets, n_flattened_ut_bins)`\n",
    "- **Features**:\n",
    "  - Contact predictions between genomic positions\n",
    "  - `diag_offset=2`: Diagonal bins masked during training\n",
    "  - Flattened upper triangle format\n",
    "  - `bin_size` and `crop_length` like 1D model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Step 2: Run 1D Predictions with TestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'seq_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize 1D model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_1d \u001b[38;5;241m=\u001b[39m \u001b[43mTestModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Predict 2 different signals\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# 1 prediction per 8bp\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Remove 10bp from each edge\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestModel (1D) configuration:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Targets: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_1d\u001b[38;5;241m.\u001b[39mn_targets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'seq_length'"
     ]
    }
   ],
   "source": [
    "# Initialize 1D model\n",
    "model_1d = TestModel(\n",
    "    seq_length=200,\n",
    "    n_targets=2,      # Predict 2 different signals\n",
    "    bin_length=8,       # 1 prediction per 8bp\n",
    "    crop_length=10    # Remove 10bp from each edge\n",
    ")\n",
    "\n",
    "print(\"TestModel (1D) configuration:\")\n",
    "print(f\"  Targets: {model_1d.n_targets}\")\n",
    "print(f\"  Bin size: {model_1d.bin_size}\")\n",
    "print(f\"  Crop length: {model_1d.crop_length}\")\n",
    "print(f\"  Input sequence length: {seq_len}\")\n",
    "print(f\"  Effective sequence length: {seq_len - 2*model_1d.crop_length}\")\n",
    "print(f\"  Number of bins: {(seq_len - 2*model_1d.crop_length) // model_1d.bin_size}\")\n",
    "\n",
    "# Run predictions\n",
    "ref_preds_1d = model_1d(ref_seqs)\n",
    "alt_preds_1d = model_1d(alt_seqs)\n",
    "\n",
    "print(f\"\\nPrediction shapes:\")\n",
    "print(f\"  Reference: {ref_preds_1d.shape}\")\n",
    "print(f\"  Alternate: {alt_preds_1d.shape}\")\n",
    "print(f\"  Format: (batch={ref_preds_1d.shape[0]}, targets={ref_preds_1d.shape[1]}, bins={ref_preds_1d.shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Step 3: Align 1D Predictions\n",
    "\n",
    "Now we align the predictions to account for coordinate changes caused by the variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align predictions for the first variant\n",
    "var_idx = 0\n",
    "\n",
    "ref_aligned_1d, alt_aligned_1d = sl.align_predictions_by_coordinate(\n",
    "    ref_pred=ref_preds_1d[var_idx],\n",
    "    alt_pred=alt_preds_1d[var_idx],\n",
    "    metadata=metadata[var_idx],\n",
    "    prediction_type=\"1D\",\n",
    "    bin_size=model_1d.bin_size,\n",
    "    crop_length=model_1d.crop_length\n",
    ")\n",
    "\n",
    "print(f\"Aligned prediction shapes:\")\n",
    "print(f\"  Reference aligned: {ref_aligned_1d.shape}\")\n",
    "print(f\"  Alternate aligned: {alt_aligned_1d.shape}\")\n",
    "\n",
    "print(f\"\\nVariant info:\")\n",
    "print(f\"  Type: {metadata[var_idx]['variant_type']}\")\n",
    "print(f\"  {metadata[var_idx]['ref']} → {metadata[var_idx]['alt']}\")\n",
    "print(f\"  Position: {metadata[var_idx]['chrom']}:{metadata[var_idx]['variant_pos1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Visualizing 1D Aligned Predictions\n",
    "\n",
    "Let's visualize how the predictions compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInterpretation:\")\n",
    "print(\"• Blue circles: Reference allele predictions\")\n",
    "print(\"• Orange squares: Alternate allele predictions\")\n",
    "print(\"• Red dashed line: Variant position\")\n",
    "print(\"• NaN values (gaps) show regions affected by indels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 4: Run 2D Predictions with TestModel2D\n",
    "\n",
    "Now let's predict contact maps (2D predictions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 2D model\n",
    "model_2d = TestModel2D(\n",
    "    n_targets=1,       # Single contact map\n",
    "    bin_size=8,        # Match 1D model\n",
    "    crop_length=10,    # Match 1D model\n",
    "    diag_offset=2      # Mask 2 diagonal bins\n",
    ")\n",
    "\n",
    "print(\"TestModel2D (Contact Map) configuration:\")\n",
    "print(f\"  Targets: {model_2d.n_targets}\")\n",
    "print(f\"  Bin size: {model_2d.bin_size}\")\n",
    "print(f\"  Crop length: {model_2d.crop_length}\")\n",
    "print(f\"  Diagonal offset: {model_2d.diag_offset}\")\n",
    "print(f\"  Input sequence length: {seq_len}\")\n",
    "print(f\"  Number of bins: {(seq_len - 2*model_2d.crop_length) // model_2d.bin_size}\")\n",
    "\n",
    "n_bins = (seq_len - 2*model_2d.crop_length) // model_2d.bin_size\n",
    "n_ut_bins = (n_bins * (n_bins - 1)) // 2 - (n_bins - model_2d.diag_offset) * model_2d.diag_offset\n",
    "print(f\"  Upper triangle bins (flattened): {n_ut_bins}\")\n",
    "\n",
    "# Run predictions\n",
    "ref_preds_2d = model_2d(ref_seqs)\n",
    "alt_preds_2d = model_2d(alt_seqs)\n",
    "\n",
    "print(f\"\\n2D Prediction shapes (flattened):\")\n",
    "print(f\"  Reference: {ref_preds_2d.shape}\")\n",
    "print(f\"  Alternate: {alt_preds_2d.shape}\")\n",
    "print(f\"  Format: (batch={ref_preds_2d.shape[0]}, targets={ref_preds_2d.shape[1]}, flattened_bins={ref_preds_2d.shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Step 5: Align 2D Predictions\n",
    "\n",
    "Aligning 2D contact maps is more complex because variants affect both dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align 2D predictions for first variant\n",
    "ref_aligned_2d, alt_aligned_2d = sl.align_predictions_by_coordinate(\n",
    "    ref_pred=ref_preds_2d[var_idx, 0],  # First target\n",
    "    alt_pred=alt_preds_2d[var_idx, 0],\n",
    "    metadata=metadata[var_idx],\n",
    "    prediction_type=\"2D\",\n",
    "    bin_size=model_2d.bin_size,\n",
    "    crop_length=model_2d.crop_length,\n",
    "    diag_offset=model_2d.diag_offset,\n",
    "    matrix_size=n_bins  # Required for 2D\n",
    ")\n",
    "\n",
    "print(f\"Aligned 2D prediction shapes:\")\n",
    "print(f\"  Reference aligned: {ref_aligned_2d.shape}\")\n",
    "print(f\"  Alternate aligned: {alt_aligned_2d.shape}\")\n",
    "print(f\"  Format: (n_bins, n_bins) - square matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Visualizing 2D Aligned Predictions (Contact Maps)\n",
    "\n",
    "Contact maps show pairwise interactions between genomic positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "ref_2d_np = ref_aligned_2d.cpu().numpy() if hasattr(ref_aligned_2d, 'cpu') else ref_aligned_2d\n",
    "alt_2d_np = alt_aligned_2d.cpu().numpy() if hasattr(alt_aligned_2d, 'cpu') else alt_aligned_2d\n",
    "\n",
    "# Create figure with three panels\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Reference contact map\n",
    "im1 = axes[0].imshow(ref_2d_np, cmap='Reds', vmin=0, vmax=1, origin='lower', interpolation='nearest')\n",
    "axes[0].set_title('Reference Contact Map', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Bin position')\n",
    "axes[0].set_ylabel('Bin position')\n",
    "plt.colorbar(im1, ax=axes[0], label='Contact strength')\n",
    "\n",
    "# Alternate contact map\n",
    "im2 = axes[1].imshow(alt_2d_np, cmap='Blues', vmin=0, vmax=1, origin='lower', interpolation='nearest')\n",
    "axes[1].set_title('Alternate Contact Map', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Bin position')\n",
    "axes[1].set_ylabel('Bin position')\n",
    "plt.colorbar(im2, ax=axes[1], label='Contact strength')\n",
    "\n",
    "# Difference map (alt - ref)\n",
    "# Only compare where both have valid values\n",
    "diff = np.where(\n",
    "    np.isnan(ref_2d_np) | np.isnan(alt_2d_np),\n",
    "    np.nan,\n",
    "    alt_2d_np - ref_2d_np\n",
    ")\n",
    "\n",
    "im3 = axes[2].imshow(diff, cmap='RdBu_r', vmin=-0.5, vmax=0.5, origin='lower', interpolation='nearest')\n",
    "axes[2].set_title('Difference (Alt - Ref)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_xlabel('Bin position')\n",
    "axes[2].set_ylabel('Bin position')\n",
    "plt.colorbar(im3, ax=axes[2], label='Δ Contact strength')\n",
    "\n",
    "# Mark variant bin position on all plots\n",
    "variant_bin = (variant_pos - effective_start) // model_2d.bin_size\n",
    "for ax in axes:\n",
    "    ax.axhline(y=variant_bin, color='lime', linestyle='--', linewidth=1, alpha=0.7)\n",
    "    ax.axvline(x=variant_bin, color='lime', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "fig.suptitle(f'2D Contact Map Alignment: {metadata[var_idx][\"variant_type\"]} Variant\\n'\n",
    "             f'{metadata[var_idx][\"chrom\"]}:{metadata[var_idx][\"variant_pos1\"]} '\n",
    "             f'{metadata[var_idx][\"ref\"]} → {metadata[var_idx][\"alt\"]}',\n",
    "             fontsize=14, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"• Left: Reference allele contact map\")\n",
    "print(\"• Middle: Alternate allele contact map\")\n",
    "print(\"• Right: Difference map (blue=decreased, red=increased contacts)\")\n",
    "print(\"• Green lines: Variant bin position\")\n",
    "print(\"• White/missing values: Regions affected by indels or masked diagonal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Understanding Diagonal Masking\n",
    "\n",
    "2D models often mask bins near the diagonal because interactions at very close distances are uninformative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize diagonal masking effect\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Create a simple example matrix\n",
    "n = 15\n",
    "example = np.ones((n, n))\n",
    "\n",
    "# Show diagonal offset effect\n",
    "diag_offset = 2\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if abs(i - j) <= diag_offset:\n",
    "            example[i, j] = np.nan\n",
    "\n",
    "# No masking\n",
    "axes[0].imshow(np.ones((n, n)), cmap='Greys', vmin=0, vmax=1, origin='lower')\n",
    "axes[0].set_title('Without Diagonal Masking', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Position')\n",
    "\n",
    "# With masking\n",
    "axes[1].imshow(example, cmap='Greys', vmin=0, vmax=1, origin='lower')\n",
    "axes[1].set_title(f'With Diagonal Masking (offset={diag_offset})', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Position')\n",
    "axes[1].set_ylabel('Position')\n",
    "\n",
    "fig.suptitle('Diagonal Masking in Contact Map Predictions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nDiagonal offset = {diag_offset} means:\")\n",
    "print(f\"  Bins within {diag_offset} positions of the diagonal are masked (NaN)\")\n",
    "print(f\"  This removes self-interactions and very short-range contacts\")\n",
    "print(f\"  TestModel2D uses diag_offset={model_2d.diag_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Comparing Multiple Variants\n",
    "\n",
    "Let's compare predictions across different variant types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNotice:\")\n",
    "print(\"• Each variant type (SNV, INS, DEL) affects predictions differently\")\n",
    "print(\"• Indels (INS/DEL) create gaps (NaN) in the alternate sequence predictions\")\n",
    "print(\"• SNVs maintain the same number of predictions for ref and alt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Key Concepts Summary\n",
    "\n",
    "### Model Architecture Components\n",
    "\n",
    "1. **Binning (`bin_size`)**\n",
    "   - Reduces resolution: 1 prediction per N base pairs\n",
    "   - Example: `bin_size=8` means 8bp → 1 prediction\n",
    "   - More efficient than per-base predictions\n",
    "\n",
    "2. **Edge Cropping (`crop_length`)**\n",
    "   - Removes bases from sequence edges before prediction\n",
    "   - Accounts for edge effects in convolutional models\n",
    "   - Example: `crop_length=10` removes 10bp from each end\n",
    "\n",
    "3. **Diagonal Masking (`diag_offset`, 2D only)**\n",
    "   - Masks bins near the diagonal in contact maps\n",
    "   - Removes self-interactions and very short-range contacts\n",
    "   - Example: `diag_offset=2` masks 2 bins from diagonal\n",
    "\n",
    "### Prediction Alignment\n",
    "\n",
    "- **Why align?** Indels shift genomic coordinates between ref and alt\n",
    "- **How?** Insert NaN bins in the shorter sequence to maintain coordinate correspondence\n",
    "- **1D alignment**: Masks affected bins in the prediction vector\n",
    "- **2D alignment**: Masks affected rows AND columns (cross-pattern for inversions)\n",
    "\n",
    "### Output Interpretation\n",
    "\n",
    "- **Solid lines/values**: Valid predictions at those genomic positions\n",
    "- **Gaps/NaN**: Regions affected by indels or diagonal masking\n",
    "- **Differences**: Where variant changes model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned the complete prediction alignment workflow:\n",
    "\n",
    "1. Generate sequences - Create ref/alt windows around variants\n",
    "2. 1D predictions - Run TestModel for genomic signal predictions\n",
    "3. 2D predictions - Run TestModel2D for contact map predictions\n",
    "4. Align predictions - Account for coordinate changes from variants\n",
    "5. Visualize results - Compare ref vs alt predictions\n",
    "6. Understand models - Binning, cropping, diagonal masking concepts\n",
    "\n",
    "This workflow is the foundation for analyzing how genetic variants affect genomic predictions.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **[04_structural_variants.ipynb](04_structural_variants.ipynb)** - Handle complex structural variants (INV, DUP, BND) with prediction alignment\n",
    "- **[05_saturation_mutagenesis.ipynb](05_saturation_mutagenesis.ipynb)** - Systematic mutagenesis and prediction analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
